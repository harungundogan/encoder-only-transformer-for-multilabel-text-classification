{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "LkI9f08-RmtQ",
      "metadata": {
        "id": "LkI9f08-RmtQ"
      },
      "source": [
        "## Data Preprocessing and Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "baseline reference for LSTM based models=https://github.com/Diwas26/Multilabel-Text-Classification-using-novel-CNN-Bi-LSTM-framework\n",
        "\n",
        "baseline reference for Transformer based models and Attention mechanism\n",
        "=https://towardsdatascience.com/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb"
      ],
      "metadata": {
        "id": "T6zUKGcbacde"
      },
      "id": "T6zUKGcbacde"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mdq83bTqyXx_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdq83bTqyXx_",
        "outputId": "cdecd2f4-0254-40e6-a884-09ee4f5cd6fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-14 11:53:18--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip [following]\n",
            "--2024-06-14 11:53:18--  https://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "WARNING: cannot verify downloads.cs.stanford.edu's certificate, issued by ‘CN=InCommon RSA Server CA,OU=InCommon,O=Internet2,L=Ann Arbor,ST=MI,C=US’:\n",
            "  Issued certificate has expired.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1520408563 (1.4G) [application/zip]\n",
            "Saving to: ‘glove.twitter.27B.zip’\n",
            "\n",
            "glove.twitter.27B.z 100%[===================>]   1.42G  5.02MB/s    in 4m 45s  \n",
            "\n",
            "2024-06-14 11:58:02 (5.09 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408563/1520408563]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.twitter.27B.zip --no-check-certificate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M8zf1fewyzUv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8zf1fewyzUv",
        "outputId": "26480e2e-94e9-437f-fc86-cbb8feda3898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.twitter.27B.zip\n",
            "  inflating: glove.twitter.27B.25d.txt  \n",
            "  inflating: glove.twitter.27B.50d.txt  \n",
            "  inflating: glove.twitter.27B.100d.txt  \n",
            "  inflating: glove.twitter.27B.200d.txt  \n"
          ]
        }
      ],
      "source": [
        "!unzip glove.twitter.27B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tfidubc1y41b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfidubc1y41b",
        "outputId": "4c18114c-019b-4cfc-c985-44c218bf8bd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive\t\t\t    glove.twitter.27B.25d.txt  sample_data\n",
            "glove.twitter.27B.100d.txt  glove.twitter.27B.50d.txt  test.csv\n",
            "glove.twitter.27B.200d.txt  glove.twitter.27B.zip      train.csv\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!ls\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mQYjiZSk4Buh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQYjiZSk4Buh",
        "outputId": "0a7f24aa-478d-4899-8fcb-550bb529f581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "with open('/content/gdrive/My Drive/train.csv', 'w') as f:\n",
        "  f.write('content')\n",
        "with open('/content/gdrive/My Drive/test.csv', 'w') as f:\n",
        "  f.write('content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc59e500-4ef7-4147-b736-51e10e6a4f11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "dc59e500-4ef7-4147-b736-51e10e6a4f11",
        "outputId": "a95ccf00-7385-406d-f981-21e10825907f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      id                                       comment_text  \\\n",
              "0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
              "1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
              "2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
              "3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
              "4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
              "...                  ...                                                ...   \n",
              "159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n",
              "159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n",
              "159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n",
              "159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n",
              "159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n",
              "\n",
              "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
              "0           0             0        0       0       0              0  \n",
              "1           0             0        0       0       0              0  \n",
              "2           0             0        0       0       0              0  \n",
              "3           0             0        0       0       0              0  \n",
              "4           0             0        0       0       0              0  \n",
              "...       ...           ...      ...     ...     ...            ...  \n",
              "159566      0             0        0       0       0              0  \n",
              "159567      0             0        0       0       0              0  \n",
              "159568      0             0        0       0       0              0  \n",
              "159569      0             0        0       0       0              0  \n",
              "159570      0             0        0       0       0              0  \n",
              "\n",
              "[159571 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f59cf781-93c1-4363-b87c-8ba7f494c9fd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159566</th>\n",
              "      <td>ffe987279560d7ff</td>\n",
              "      <td>\":::::And for the second time of asking, when ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159567</th>\n",
              "      <td>ffea4adeee384e90</td>\n",
              "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159568</th>\n",
              "      <td>ffee36eab5c267c9</td>\n",
              "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159569</th>\n",
              "      <td>fff125370e4aaaf3</td>\n",
              "      <td>And it looks like it was actually you who put ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159570</th>\n",
              "      <td>fff46fc426af1f9a</td>\n",
              "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>159571 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f59cf781-93c1-4363-b87c-8ba7f494c9fd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f59cf781-93c1-4363-b87c-8ba7f494c9fd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f59cf781-93c1-4363-b87c-8ba7f494c9fd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7cce17f0-aa8d-4abc-8505-c038f0d05bfe\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7cce17f0-aa8d-4abc-8505-c038f0d05bfe')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7cce17f0-aa8d-4abc-8505-c038f0d05bfe button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_78bdc987-5d5c-4e27-b71d-3fef6f81881a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_78bdc987-5d5c-4e27-b71d-3fef6f81881a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d36f4d4b-36b5-4f32-9836-eed5c9f133a7",
      "metadata": {
        "id": "d36f4d4b-36b5-4f32-9836-eed5c9f133a7"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def preprocess(text):\n",
        "    text = re.sub(r\"[^a-zA-Z0-9ğüşöçıİĞÜŞÖÇ\\s]\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    text = text.lower()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc53468e-50dd-456b-a77e-a17008d57fd0",
      "metadata": {
        "id": "bc53468e-50dd-456b-a77e-a17008d57fd0"
      },
      "outputs": [],
      "source": [
        "df[\"comment_text\"] = df[\"comment_text\"].apply(lambda x: preprocess(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a3f4d1b-2ee7-40ad-83c3-7f6986d7571c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "9a3f4d1b-2ee7-40ad-83c3-7f6986d7571c",
        "outputId": "dde40806-0a64-4fc4-edf8-1b199b556a9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      id                                       comment_text  \\\n",
              "0       0000997932d777bf  explanation why the edits made under my userna...   \n",
              "1       000103f0d9cfb60f  daww he matches this background colour im seem...   \n",
              "2       000113f07ec002fd  hey man im really not trying to edit war its j...   \n",
              "3       0001b41b1c6bb37e   more i cant make any real suggestions on impr...   \n",
              "4       0001d958c54c6e35  you sir are my hero any chance you remember wh...   \n",
              "...                  ...                                                ...   \n",
              "159566  ffe987279560d7ff  and for the second time of asking when your vi...   \n",
              "159567  ffea4adeee384e90  you should be ashamed of yourself that is a ho...   \n",
              "159568  ffee36eab5c267c9  spitzer umm theres no actual article for prost...   \n",
              "159569  fff125370e4aaaf3  and it looks like it was actually you who put ...   \n",
              "159570  fff46fc426af1f9a   and i really dont think you understand i came...   \n",
              "\n",
              "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
              "0           0             0        0       0       0              0  \n",
              "1           0             0        0       0       0              0  \n",
              "2           0             0        0       0       0              0  \n",
              "3           0             0        0       0       0              0  \n",
              "4           0             0        0       0       0              0  \n",
              "...       ...           ...      ...     ...     ...            ...  \n",
              "159566      0             0        0       0       0              0  \n",
              "159567      0             0        0       0       0              0  \n",
              "159568      0             0        0       0       0              0  \n",
              "159569      0             0        0       0       0              0  \n",
              "159570      0             0        0       0       0              0  \n",
              "\n",
              "[159571 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cedac5d4-0a27-4d73-8289-d89f38c7646e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>explanation why the edits made under my userna...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>daww he matches this background colour im seem...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>hey man im really not trying to edit war its j...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>more i cant make any real suggestions on impr...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>you sir are my hero any chance you remember wh...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159566</th>\n",
              "      <td>ffe987279560d7ff</td>\n",
              "      <td>and for the second time of asking when your vi...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159567</th>\n",
              "      <td>ffea4adeee384e90</td>\n",
              "      <td>you should be ashamed of yourself that is a ho...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159568</th>\n",
              "      <td>ffee36eab5c267c9</td>\n",
              "      <td>spitzer umm theres no actual article for prost...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159569</th>\n",
              "      <td>fff125370e4aaaf3</td>\n",
              "      <td>and it looks like it was actually you who put ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159570</th>\n",
              "      <td>fff46fc426af1f9a</td>\n",
              "      <td>and i really dont think you understand i came...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>159571 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cedac5d4-0a27-4d73-8289-d89f38c7646e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cedac5d4-0a27-4d73-8289-d89f38c7646e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cedac5d4-0a27-4d73-8289-d89f38c7646e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c571726b-7acb-4efb-877f-47187ab3ce25\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c571726b-7acb-4efb-877f-47187ab3ce25')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c571726b-7acb-4efb-877f-47187ab3ce25 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3dabf40e-bafd-43ad-891a-1e7e92f82987\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3dabf40e-bafd-43ad-891a-1e7e92f82987 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c69a748b-5b27-4698-8e72-2d04564c5433",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c69a748b-5b27-4698-8e72-2d04564c5433",
        "outputId": "6d585ff4-cdbf-404f-859f-b12c93ebbe77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toxic\n",
            "0    144277\n",
            "1     15294\n",
            "Name: count, dtype: int64\n",
            "severe_toxic\n",
            "0    157976\n",
            "1      1595\n",
            "Name: count, dtype: int64\n",
            "obscene\n",
            "0    151122\n",
            "1      8449\n",
            "Name: count, dtype: int64\n",
            "threat\n",
            "0    159093\n",
            "1       478\n",
            "Name: count, dtype: int64\n",
            "insult\n",
            "0    151694\n",
            "1      7877\n",
            "Name: count, dtype: int64\n",
            "identity_hate\n",
            "0    158166\n",
            "1      1405\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "for i in df.columns[2:]:\n",
        "\n",
        "    print(df[i].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14f48ac8-c230-4ba7-bf53-a0df62341e55",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "14f48ac8-c230-4ba7-bf53-a0df62341e55",
        "outputId": "aa418994-a3bb-4fd0-ca75-5882a4cb1f68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      id                                       comment_text  \\\n",
              "0       0000997932d777bf  explanation why the edits made under my userna...   \n",
              "1       000103f0d9cfb60f  daww he matches this background colour im seem...   \n",
              "2       000113f07ec002fd  hey man im really not trying to edit war its j...   \n",
              "3       0001b41b1c6bb37e   more i cant make any real suggestions on impr...   \n",
              "4       0001d958c54c6e35  you sir are my hero any chance you remember wh...   \n",
              "...                  ...                                                ...   \n",
              "159566  ffe987279560d7ff  and for the second time of asking when your vi...   \n",
              "159567  ffea4adeee384e90  you should be ashamed of yourself that is a ho...   \n",
              "159568  ffee36eab5c267c9  spitzer umm theres no actual article for prost...   \n",
              "159569  fff125370e4aaaf3  and it looks like it was actually you who put ...   \n",
              "159570  fff46fc426af1f9a   and i really dont think you understand i came...   \n",
              "\n",
              "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
              "0           0             0        0       0       0              0  \n",
              "1           0             0        0       0       0              0  \n",
              "2           0             0        0       0       0              0  \n",
              "3           0             0        0       0       0              0  \n",
              "4           0             0        0       0       0              0  \n",
              "...       ...           ...      ...     ...     ...            ...  \n",
              "159566      0             0        0       0       0              0  \n",
              "159567      0             0        0       0       0              0  \n",
              "159568      0             0        0       0       0              0  \n",
              "159569      0             0        0       0       0              0  \n",
              "159570      0             0        0       0       0              0  \n",
              "\n",
              "[159571 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ebae2bd-15ef-454c-b2a8-c2af62a27d65\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>explanation why the edits made under my userna...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>daww he matches this background colour im seem...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>hey man im really not trying to edit war its j...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>more i cant make any real suggestions on impr...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>you sir are my hero any chance you remember wh...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159566</th>\n",
              "      <td>ffe987279560d7ff</td>\n",
              "      <td>and for the second time of asking when your vi...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159567</th>\n",
              "      <td>ffea4adeee384e90</td>\n",
              "      <td>you should be ashamed of yourself that is a ho...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159568</th>\n",
              "      <td>ffee36eab5c267c9</td>\n",
              "      <td>spitzer umm theres no actual article for prost...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159569</th>\n",
              "      <td>fff125370e4aaaf3</td>\n",
              "      <td>and it looks like it was actually you who put ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159570</th>\n",
              "      <td>fff46fc426af1f9a</td>\n",
              "      <td>and i really dont think you understand i came...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>159571 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ebae2bd-15ef-454c-b2a8-c2af62a27d65')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5ebae2bd-15ef-454c-b2a8-c2af62a27d65 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5ebae2bd-15ef-454c-b2a8-c2af62a27d65');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cdda30b8-b6b0-46b0-b28b-13ad4e2e92f5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cdda30b8-b6b0-46b0-b28b-13ad4e2e92f5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cdda30b8-b6b0-46b0-b28b-13ad4e2e92f5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_552d61ed-2e34-4b77-a98d-f48f3476e5f2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_552d61ed-2e34-4b77-a98d-f48f3476e5f2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wS0kmK4K4lRe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wS0kmK4K4lRe",
        "outputId": "c57e31a3-50e4-4c4b-912b-e72850347862"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d870209-2d9a-4f23-961e-1f0ff4d42873",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d870209-2d9a-4f23-961e-1f0ff4d42873",
        "outputId": "46d95885-274c-49c0-c662-9c5455f3b1ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (24.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e641762-3519-4683-a1af-a2509c012c76",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e641762-3519-4683-a1af-a2509c012c76",
        "outputId": "8368cf4a-2413-4981-b739-e4e0ba1b723e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten, LSTM\n",
        "from keras.layers import Bidirectional,GRU,concatenate,SpatialDropout1D\n",
        "from keras.layers import GlobalMaxPooling1D,GlobalAveragePooling1D,Conv1D\n",
        "from keras.models import Model\n",
        "from keras.layers import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Input\n",
        "from keras.layers import Concatenate\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "from keras.optimizers import Adam,SGD,RMSprop\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N96hau6FR_M1",
      "metadata": {
        "id": "N96hau6FR_M1"
      },
      "source": [
        "  ## Evaluation Metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55f4822b-a866-40e4-9e90-1e14366f69b2",
      "metadata": {
        "id": "55f4822b-a866-40e4-9e90-1e14366f69b2"
      },
      "outputs": [],
      "source": [
        "def micro_f1_score(y_true, y_pred):\n",
        "    true_positives = tf.reduce_sum(tf.cast(tf.math.logical_and(tf.cast(y_true, tf.bool), tf.cast(y_pred, tf.bool)), tf.float32), axis=0)\n",
        "    predicted_positives = tf.reduce_sum(tf.cast(y_pred, tf.float32), axis=0)\n",
        "    actual_positives = tf.reduce_sum(tf.cast(y_true, tf.float32), axis=0)\n",
        "\n",
        "    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n",
        "    recall = true_positives / (actual_positives + tf.keras.backend.epsilon())\n",
        "\n",
        "    micro_f1 = tf.reduce_mean(2 * precision * recall / (precision + recall + tf.keras.backend.epsilon()))\n",
        "\n",
        "    return micro_f1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, GlobalAveragePooling1D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "def sigmoid_cross_entropy_with_logits(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.cast(y_true, tf.float32), logits=y_pred))"
      ],
      "metadata": {
        "id": "tYXfwBqDloQ2"
      },
      "id": "tYXfwBqDloQ2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def distribution_balanced_loss(y_true, y_pred, beta=0.99, gamma=2.0):\n",
        "    # Number of samples per class\n",
        "    sample_counts = tf.reduce_sum(y_true, axis=0)\n",
        "\n",
        "    # Cast sample_counts to float32\n",
        "    sample_counts = tf.cast(sample_counts, tf.float32)\n",
        "\n",
        "    # Effective number of samples\n",
        "    effective_num = 1.0 - tf.pow(beta, sample_counts)\n",
        "    weights = (1.0 - beta) / effective_num\n",
        "\n",
        "    # Normalize weights\n",
        "    weights = weights / tf.reduce_sum(weights) * tf.cast(tf.shape(y_true)[0], tf.float32)\n",
        "\n",
        "    # Cast y_true to float32\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "\n",
        "    # Compute binary cross entropy loss\n",
        "    bce = K.binary_crossentropy(y_true, y_pred)\n",
        "\n",
        "    # Apply weights\n",
        "    loss = tf.reduce_sum(bce * weights, axis=-1)\n",
        "\n",
        "    return loss\n",
        "\n"
      ],
      "metadata": {
        "id": "csjNTuOEsuMT"
      },
      "id": "csjNTuOEsuMT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "_Onm5TusSRoP",
      "metadata": {
        "id": "_Onm5TusSRoP"
      },
      "source": [
        "## Simple LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed28c804-31d2-478d-b944-f4bc2cef006c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed28c804-31d2-478d-b944-f4bc2cef006c",
        "outputId": "d536e945-1bfe-4253-f5b5-d2c95302b77b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159571 entries, 0 to 159570\n",
            "Data columns (total 8 columns):\n",
            " #   Column         Non-Null Count   Dtype \n",
            "---  ------         --------------   ----- \n",
            " 0   id             159571 non-null  object\n",
            " 1   comment_text   159571 non-null  object\n",
            " 2   toxic          159571 non-null  int64 \n",
            " 3   severe_toxic   159571 non-null  int64 \n",
            " 4   obscene        159571 non-null  int64 \n",
            " 5   threat         159571 non-null  int64 \n",
            " 6   insult         159571 non-null  int64 \n",
            " 7   identity_hate  159571 non-null  int64 \n",
            "dtypes: int64(6), object(2)\n",
            "memory usage: 9.7+ MB\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "\n",
        "df = pd.read_csv(r\"train.csv\", encoding='iso-8859-1')\n",
        "df.info()\n",
        "df.head(n=5)\n",
        "\n",
        "df_data = df.sample(frac=0.2, replace=True, random_state=1)\n",
        "\n",
        "df_data.isnull().sum()\n",
        "\n",
        "wpt = nltk.WordPunctTokenizer()\n",
        "stop_words_init = nltk.corpus.stopwords.words('english')\n",
        "stop_words = [i for i in stop_words_init if i not in ('not','and','for')]\n",
        "print(stop_words)\n",
        "\n",
        "def normalize_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', ' ', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', ' ', text)\n",
        "    text = re.sub('<.*?>+', ' ', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
        "    text = re.sub('\\n', ' ', text)\n",
        "    text = re.sub('\\w*\\d\\w*', ' ', text)\n",
        "    return text\n",
        "\n",
        "df_data['comment_text'] = df_data['comment_text'].apply(lambda x: normalize_text(x))\n",
        "\n",
        "df_data['comment_text'].head(n=5)\n",
        "\n",
        "processed_list = []\n",
        "for j in df_data['comment_text']:\n",
        "    process = j.replace('...','')\n",
        "    processed_list.append(process)\n",
        "\n",
        "df_processed = pd.DataFrame(processed_list)\n",
        "df_processed.columns = ['comments']\n",
        "df_processed.head(n=5)\n",
        "\n",
        "\n",
        "labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "targets = df_data[labels].values\n",
        "\n",
        "\n",
        "X = list(df_processed['comments'])\n",
        "y_data = df_data[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]]\n",
        "y = y_data.values\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.20, train_size=0.80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c294077-7d9c-4e0e-bffe-5af8d2a90815",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c294077-7d9c-4e0e-bffe-5af8d2a90815",
        "outputId": "36e23e8f-1740-43f5-8318-1619909641fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 100)]             0         \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 100, 200)          2000000   \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 100, 128)          168448    \n",
            "                                                                 \n",
            " global_average_pooling1d_5  (None, 128)               0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 6)                 774       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2185734 (8.34 MB)\n",
            "Trainable params: 185734 (725.52 KB)\n",
            "Non-trainable params: 2000000 (7.63 MB)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 86s 485ms/step - loss: 0.1522 - micro_f1_score: 0.7896 - val_loss: 0.0931 - val_micro_f1_score: 0.9346\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 78s 489ms/step - loss: 0.0740 - micro_f1_score: 0.8172 - val_loss: 0.0652 - val_micro_f1_score: 0.7584\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 101s 631ms/step - loss: 0.0609 - micro_f1_score: 0.8258 - val_loss: 0.0579 - val_micro_f1_score: 0.8530\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 76s 472ms/step - loss: 0.0567 - micro_f1_score: 0.8219 - val_loss: 0.0549 - val_micro_f1_score: 0.8902\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 75s 467ms/step - loss: 0.0543 - micro_f1_score: 0.8327 - val_loss: 0.0593 - val_micro_f1_score: 0.9584\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 93s 579ms/step - loss: 0.0524 - micro_f1_score: 0.8197 - val_loss: 0.0532 - val_micro_f1_score: 0.9039\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 76s 472ms/step - loss: 0.0512 - micro_f1_score: 0.8308 - val_loss: 0.0528 - val_micro_f1_score: 0.8510\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 75s 466ms/step - loss: 0.0501 - micro_f1_score: 0.8210 - val_loss: 0.0523 - val_micro_f1_score: 0.8711\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 93s 582ms/step - loss: 0.0483 - micro_f1_score: 0.8274 - val_loss: 0.0527 - val_micro_f1_score: 0.8825\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 74s 462ms/step - loss: 0.0481 - micro_f1_score: 0.8307 - val_loss: 0.0518 - val_micro_f1_score: 0.8477\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.0578 - micro_f1_score: 0.5760\n",
            "Micro F1 Score 0.576042890548706\n"
          ]
        }
      ],
      "source": [
        "max_len = 100\n",
        "max_features = 10000\n",
        "embed_size = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(x_train)+list(x_test))\n",
        "\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_test= tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "\n",
        "x_train = pad_sequences(x_train, padding='post', maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, padding='post', maxlen=max_len)\n",
        "\n",
        "\n",
        "\n",
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "\n",
        "glove_file = open('glove.twitter.27B.200d.txt', encoding=\"utf8\") ## using pre-trained or self-trained embeddings ##\n",
        "\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary[word] = vector_dimensions\n",
        "glove_file.close()\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1  ## total distinct words is the Vocabulary ##\n",
        "word_index = tokenizer.word_index\n",
        "num_words = min(max_features,len(word_index)+1)\n",
        "\n",
        "embedding_matrix = zeros((num_words, embed_size)) ## has to be similar to glove dimension ##\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index >= max_features:\n",
        "        continue\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector\n",
        "\n",
        "sequence_input = Input(shape=(max_len,))\n",
        "x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(sequence_input)\n",
        "x = LSTM(128, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)(x)\n",
        "avg_pool = GlobalAveragePooling1D()(x)\n",
        "x = Dense(128, activation='relu')(avg_pool)\n",
        "x = Dropout(0.1)(x)\n",
        "preds = Dense(6, activation=\"sigmoid\")(x)  # Keep activation as sigmoid\n",
        "model = Model(sequence_input, preds)\n",
        "sfc_loss = tfa.losses.SigmoidFocalCrossEntropy()\n",
        "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(1e-3), metrics=[micro_f1_score])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=128, epochs=10,\n",
        "                    verbose=1, validation_split=0.2)\n",
        "\n",
        "model.save_weights(\"./LSTM_ver1.h5\")\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print(\"Micro F1 Score\", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O-S83KJEWNna",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-S83KJEWNna",
        "outputId": "083729c4-4932-41b7-865a-4f0080cbc6fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200/200 [==============================] - 11s 52ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class_0       0.80      0.72      0.76       613\n",
            "     class_1       0.50      0.10      0.17        58\n",
            "     class_2       0.82      0.74      0.78       359\n",
            "     class_3       0.00      0.00      0.00        22\n",
            "     class_4       0.73      0.65      0.69       315\n",
            "     class_5       0.00      0.00      0.00        48\n",
            "\n",
            "   micro avg       0.79      0.65      0.71      1415\n",
            "   macro avg       0.47      0.37      0.40      1415\n",
            "weighted avg       0.74      0.65      0.69      1415\n",
            " samples avg       0.06      0.06      0.06      1415\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "y_pred_probs = model.predict(x_test)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "# Generate the classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=[f'class_{i}' for i in range(6)]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vC8ZqxXTSZqb",
      "metadata": {
        "id": "vC8ZqxXTSZqb"
      },
      "source": [
        " ## Bidirectional LSTM with Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sveqMdGGn-DD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sveqMdGGn-DD",
        "outputId": "c6360b48-a12a-4a74-b212-f879201bd722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159571 entries, 0 to 159570\n",
            "Data columns (total 8 columns):\n",
            " #   Column         Non-Null Count   Dtype \n",
            "---  ------         --------------   ----- \n",
            " 0   id             159571 non-null  object\n",
            " 1   comment_text   159571 non-null  object\n",
            " 2   toxic          159571 non-null  int64 \n",
            " 3   severe_toxic   159571 non-null  int64 \n",
            " 4   obscene        159571 non-null  int64 \n",
            " 5   threat         159571 non-null  int64 \n",
            " 6   insult         159571 non-null  int64 \n",
            " 7   identity_hate  159571 non-null  int64 \n",
            "dtypes: int64(6), object(2)\n",
            "memory usage: 9.7+ MB\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "\n",
        "df = pd.read_csv(r\"train.csv\", encoding='iso-8859-1')\n",
        "df.info()\n",
        "df.head(n=5)\n",
        "\n",
        "df_data = df.sample(frac=0.2, replace=True, random_state=1)\n",
        "\n",
        "df_data.isnull().sum()\n",
        "\n",
        "wpt = nltk.WordPunctTokenizer()\n",
        "stop_words_init = nltk.corpus.stopwords.words('english')\n",
        "stop_words = [i for i in stop_words_init if i not in ('not','and','for')]\n",
        "print(stop_words)\n",
        "\n",
        "## Function to normalize text for pre-processing ##\n",
        "def normalize_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', ' ', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', ' ', text)\n",
        "    text = re.sub('<.*?>+', ' ', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
        "    text = re.sub('\\n', ' ', text)\n",
        "    text = re.sub('\\w*\\d\\w*', ' ', text)\n",
        "    return text\n",
        "\n",
        "## Apply the written function ##\n",
        "df_data['comment_text'] = df_data['comment_text'].apply(lambda x: normalize_text(x))\n",
        "\n",
        "df_data['comment_text'].head(n=5)\n",
        "\n",
        "processed_list = []\n",
        "for j in df_data['comment_text']:\n",
        "    process = j.replace('...','')\n",
        "    processed_list.append(process)\n",
        "\n",
        "df_processed = pd.DataFrame(processed_list)\n",
        "df_processed.columns = ['comments']\n",
        "df_processed.head(n=5)\n",
        "\n",
        "\n",
        "labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "targets = df_data[labels].values\n",
        "\n",
        "\n",
        "X = list(df_processed['comments'])\n",
        "y_data = df_data[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]]\n",
        "y = y_data.values\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.20, train_size=0.80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7412d5e1-0429-4f52-ae11-5194000d1a0c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7412d5e1-0429-4f52-ae11-5194000d1a0c",
        "outputId": "a5c3e470-621b-4e24-eebb-19c71ef5c3c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 100)]             0         \n",
            "                                                                 \n",
            " embedding_6 (Embedding)     (None, 100, 200)          2000000   \n",
            "                                                                 \n",
            " spatial_dropout1d (Spatial  (None, 100, 200)          0         \n",
            " Dropout1D)                                                      \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 98, 64)            38464     \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 98, 256)           197632    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " global_average_pooling1d_6  (None, 256)               0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 6)                 774       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2269766 (8.66 MB)\n",
            "Trainable params: 269766 (1.03 MB)\n",
            "Non-trainable params: 2000000 (7.63 MB)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 167s 961ms/step - loss: 0.1408 - micro_f1_score: 0.7938 - val_loss: 0.0903 - val_micro_f1_score: 0.8357\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 173s 1s/step - loss: 0.0785 - micro_f1_score: 0.8165 - val_loss: 0.0673 - val_micro_f1_score: 0.9898\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 166s 1s/step - loss: 0.0639 - micro_f1_score: 0.8319 - val_loss: 0.0571 - val_micro_f1_score: 0.8579\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 153s 952ms/step - loss: 0.0602 - micro_f1_score: 0.8380 - val_loss: 0.0563 - val_micro_f1_score: 0.8881\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 172s 1s/step - loss: 0.0580 - micro_f1_score: 0.8331 - val_loss: 0.0537 - val_micro_f1_score: 0.8504\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 162s 1s/step - loss: 0.0556 - micro_f1_score: 0.8248 - val_loss: 0.0536 - val_micro_f1_score: 0.8380\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 157s 982ms/step - loss: 0.0548 - micro_f1_score: 0.8347 - val_loss: 0.0530 - val_micro_f1_score: 0.8900\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 161s 1s/step - loss: 0.0529 - micro_f1_score: 0.8385 - val_loss: 0.0524 - val_micro_f1_score: 0.8656\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 156s 976ms/step - loss: 0.0514 - micro_f1_score: 0.8348 - val_loss: 0.0518 - val_micro_f1_score: 0.8854\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 161s 1s/step - loss: 0.0499 - micro_f1_score: 0.8242 - val_loss: 0.0510 - val_micro_f1_score: 0.9191\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0565 - micro_f1_score: 0.6210\n",
            "Loss:  0.05653883144259453\n",
            "Micro F1 Score:  0.6209552884101868\n"
          ]
        }
      ],
      "source": [
        "max_len = 100\n",
        "max_features = 10000\n",
        "embed_size = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(x_train)+list(x_test))\n",
        "\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_test= tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "\n",
        "x_train = pad_sequences(x_train, padding='post', maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, padding='post', maxlen=max_len)\n",
        "\n",
        "\n",
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "\n",
        "glove_file = open('glove.twitter.27B.200d.txt', encoding=\"utf8\") ## using pre-trained or self-trained embeddings ##\n",
        "\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary[word] = vector_dimensions\n",
        "glove_file.close()\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1  ## total distinct words is the Vocabulary ##\n",
        "word_index = tokenizer.word_index\n",
        "num_words = min(max_features,len(word_index)+1)\n",
        "\n",
        "embedding_matrix = zeros((num_words, embed_size)) ## has to be similar to glove dimension ##\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index >= max_features:\n",
        "        continue\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector\n",
        "\n",
        "\n",
        "sequence_input = Input(shape=(max_len, ))\n",
        "x = Embedding(max_features, embed_size, weights=[embedding_matrix],trainable = False)(sequence_input)\n",
        "x = SpatialDropout1D(0.2)(x)\n",
        "x = Conv1D(64, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x)\n",
        "x = Bidirectional(LSTM(128, return_sequences=True,dropout=0.1,recurrent_dropout=0.1))(x)\n",
        "avg_pool = GlobalAveragePooling1D()(x)\n",
        "x = Dense(128, activation='relu')(avg_pool)\n",
        "x = Dropout(0.1)(x)\n",
        "preds = Dense(6, activation=\"sigmoid\")(x)\n",
        "model = Model(sequence_input, preds)\n",
        "sfc_loss = tfa.losses.SigmoidFocalCrossEntropy()\n",
        "model.compile(loss='binary_crossentropy',optimizer=tf.keras.optimizers.Adam(1e-3),metrics=[micro_f1_score])\n",
        "print(model.summary())\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=128, epochs=10,\n",
        "                    verbose=1, validation_split=0.2)\n",
        "\n",
        "model.save_weights(\"./BiLSTM_ver2.h5\")\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print(\"Loss: \", score[0])\n",
        "print(\"Micro F1 Score: \", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5NkhU2cvcqFZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NkhU2cvcqFZ",
        "outputId": "5cdd1f30-641d-4ad9-bcc4-3454da23ec86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200/200 [==============================] - 19s 93ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        toxic       0.90      0.62      0.74       612\n",
            " severe_toxic       0.50      0.20      0.29        50\n",
            "      obscene       0.85      0.69      0.76       329\n",
            "       threat       0.00      0.00      0.00        20\n",
            "       insult       0.70      0.64      0.67       293\n",
            "identity_hate       0.00      0.00      0.00        51\n",
            "\n",
            "    micro avg       0.82      0.59      0.69      1355\n",
            "    macro avg       0.49      0.36      0.41      1355\n",
            " weighted avg       0.78      0.59      0.67      1355\n",
            "  samples avg       0.05      0.05      0.05      1355\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "y_pred_probs = model.predict(x_test)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "# Generate the classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9jwEnczKSqvu",
      "metadata": {
        "id": "9jwEnczKSqvu"
      },
      "source": [
        "## Conv-Bidirectional LSTM with Multi-Head Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cebf42c2-a9e1-4204-8781-cc26ab7b36ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cebf42c2-a9e1-4204-8781-cc26ab7b36ae",
        "outputId": "5701a632-71b6-4136-e9f2-f49b0a75cb0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159571 entries, 0 to 159570\n",
            "Data columns (total 8 columns):\n",
            " #   Column         Non-Null Count   Dtype \n",
            "---  ------         --------------   ----- \n",
            " 0   id             159571 non-null  object\n",
            " 1   comment_text   159571 non-null  object\n",
            " 2   toxic          159571 non-null  int64 \n",
            " 3   severe_toxic   159571 non-null  int64 \n",
            " 4   obscene        159571 non-null  int64 \n",
            " 5   threat         159571 non-null  int64 \n",
            " 6   insult         159571 non-null  int64 \n",
            " 7   identity_hate  159571 non-null  int64 \n",
            "dtypes: int64(6), object(2)\n",
            "memory usage: 9.7+ MB\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "\n",
        "df = pd.read_csv(r\"train.csv\", encoding='iso-8859-1')\n",
        "df.info()\n",
        "df.head(n=5)\n",
        "\n",
        "df_data = df.sample(frac=0.2, replace=True, random_state=1)\n",
        "\n",
        "df_data.isnull().sum()\n",
        "\n",
        "wpt = nltk.WordPunctTokenizer()\n",
        "stop_words_init = nltk.corpus.stopwords.words('english')\n",
        "stop_words = [i for i in stop_words_init if i not in ('not','and','for')]\n",
        "print(stop_words)\n",
        "\n",
        "## Function to normalize text for pre-processing ##\n",
        "def normalize_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', ' ', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', ' ', text)\n",
        "    text = re.sub('<.*?>+', ' ', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
        "    text = re.sub('\\n', ' ', text)\n",
        "    text = re.sub('\\w*\\d\\w*', ' ', text)\n",
        "    return text\n",
        "\n",
        "## Apply the written function ##\n",
        "df_data['comment_text'] = df_data['comment_text'].apply(lambda x: normalize_text(x))\n",
        "\n",
        "df_data['comment_text'].head(n=5)\n",
        "\n",
        "processed_list = []\n",
        "for j in df_data['comment_text']:\n",
        "    process = j.replace('...','')\n",
        "    processed_list.append(process)\n",
        "\n",
        "df_processed = pd.DataFrame(processed_list)\n",
        "df_processed.columns = ['comments']\n",
        "df_processed.head(n=5)\n",
        "\n",
        "\n",
        "labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "targets = df_data[labels].values\n",
        "\n",
        "\n",
        "X = list(df_processed['comments'])\n",
        "y_data = df_data[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]]\n",
        "y = y_data.values\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.20, train_size=0.80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b03cd3b1-19e9-46db-ab8e-ccf704b7bf83",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b03cd3b1-19e9-46db-ab8e-ccf704b7bf83",
        "outputId": "2f11815f-8ab5-4bb8-b9d2-a1d1f8e595a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 100)]             0         \n",
            "                                                                 \n",
            " embedding_7 (Embedding)     (None, 100, 200)          2000000   \n",
            "                                                                 \n",
            " spatial_dropout1d_1 (Spati  (None, 100, 200)          0         \n",
            " alDropout1D)                                                    \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 98, 64)            38464     \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 98, 256)           197632    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " multi_head_self_attention   (None, 98, 256)           1643968   \n",
            " (MultiHeadSelfAttention)                                        \n",
            "                                                                 \n",
            " global_average_pooling1d_7  (None, 256)               0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 6)                 1542      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3881606 (14.81 MB)\n",
            "Trainable params: 1881606 (7.18 MB)\n",
            "Non-trainable params: 2000000 (7.63 MB)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 179s 1s/step - loss: 0.0993 - micro_f1_score: 0.8662 - val_loss: 0.0631 - val_micro_f1_score: 0.9004\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 167s 1s/step - loss: 0.0631 - micro_f1_score: 0.8217 - val_loss: 0.0579 - val_micro_f1_score: 0.9139\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 178s 1s/step - loss: 0.0597 - micro_f1_score: 0.8463 - val_loss: 0.0585 - val_micro_f1_score: 0.8806\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 161s 1s/step - loss: 0.0575 - micro_f1_score: 0.8431 - val_loss: 0.0534 - val_micro_f1_score: 0.8458\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 172s 1s/step - loss: 0.0544 - micro_f1_score: 0.8423 - val_loss: 0.0547 - val_micro_f1_score: 0.8303\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 183s 1s/step - loss: 0.0530 - micro_f1_score: 0.8236 - val_loss: 0.0552 - val_micro_f1_score: 0.9574\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 158s 986ms/step - loss: 0.0508 - micro_f1_score: 0.8430 - val_loss: 0.0527 - val_micro_f1_score: 0.8549\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 178s 1s/step - loss: 0.0497 - micro_f1_score: 0.8276 - val_loss: 0.0577 - val_micro_f1_score: 0.9612\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 176s 1s/step - loss: 0.0479 - micro_f1_score: 0.8215 - val_loss: 0.0507 - val_micro_f1_score: 0.8901\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 154s 962ms/step - loss: 0.0456 - micro_f1_score: 0.8282 - val_loss: 0.0514 - val_micro_f1_score: 0.8683\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0524 - micro_f1_score: 0.5866\n",
            "Micro F1 Score:  0.5865552425384521\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, MultiHeadAttention, LayerNormalization, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, Embedding, SpatialDropout1D, Conv1D, Bidirectional, LSTM, GlobalAveragePooling1D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import numpy as np\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "# Textual Features for Embedding\n",
        "max_len = 100\n",
        "max_features = 10000\n",
        "embed_size = 200\n",
        "\n",
        "# Assuming x_train and x_test are predefined\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(x_train) + list(x_test))\n",
        "\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_test = tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "x_train = pad_sequences(x_train, padding='post', maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, padding='post', maxlen=max_len)\n",
        "\n",
        "# Loading pre-trained GloVe embeddings\n",
        "embeddings_dictionary = {}\n",
        "with open('glove.twitter.27B.200d.txt', encoding=\"utf8\") as glove_file:\n",
        "    for line in glove_file:\n",
        "        records = line.split()\n",
        "        word = records[0]\n",
        "        vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
        "        embeddings_dictionary[word] = vector_dimensions\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "word_index = tokenizer.word_index\n",
        "num_words = min(max_features, len(word_index) + 1)\n",
        "\n",
        "embedding_matrix = np.zeros((num_words, embed_size))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index >= max_features:\n",
        "        continue\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector\n",
        "\n",
        "# Multi-Head Attention Layer\n",
        "class MultiHeadSelfAttention(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, **kwargs):\n",
        "        super(MultiHeadSelfAttention, self).__init__(**kwargs)\n",
        "        self.mha = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.layernorm = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout = Dropout(0.1)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.mha(inputs, inputs)\n",
        "        attn_output = self.dropout(attn_output, training=training)\n",
        "        return self.layernorm(inputs + attn_output)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "# Building the Model\n",
        "sequence_input = Input(shape=(max_len,))\n",
        "embedding_layer = Embedding(num_words, embed_size, weights=[embedding_matrix], trainable=False)(sequence_input)\n",
        "x = SpatialDropout1D(0.2)(embedding_layer)\n",
        "x = Conv1D(64, kernel_size=3, padding=\"valid\", kernel_initializer=\"glorot_uniform\")(x)\n",
        "x = Bidirectional(LSTM(128, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
        "x = MultiHeadSelfAttention(embed_dim=embed_size, num_heads=8)(x)\n",
        "x = GlobalAveragePooling1D()(x)\n",
        "x = Dropout(0.1)(x)\n",
        "preds = Dense(6, activation=\"sigmoid\")(x)\n",
        "model = Model(sequence_input, preds)\n",
        "\n",
        "sfc_loss = tfa.losses.SigmoidFocalCrossEntropy()\n",
        "model.compile(loss='binary_crossentropy' , optimizer=tf.keras.optimizers.Adam(1e-3), metrics=[micro_f1_score])\n",
        "print(model.summary())\n",
        "\n",
        "# Assuming y_train and y_test are predefined\n",
        "history = model.fit(x_train, y_train, batch_size=128, epochs=10, verbose=1, validation_split=0.2)\n",
        "\n",
        "model.save_weights(\"./BiLSTM_MultiHeadAttention_Ver1.h5\")\n",
        "# Scoring on Validation set\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "print(\"Micro F1 Score: \", score[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eH2IeMLzdavD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eH2IeMLzdavD",
        "outputId": "2cbcf571-d529-4277-8d4c-13fe204aedb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200/200 [==============================] - 19s 94ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        toxic       0.87      0.64      0.74       585\n",
            " severe_toxic       0.58      0.54      0.56        54\n",
            "      obscene       0.89      0.75      0.81       314\n",
            "       threat       0.33      0.05      0.09        20\n",
            "       insult       0.81      0.62      0.70       283\n",
            "identity_hate       0.48      0.27      0.35        55\n",
            "\n",
            "    micro avg       0.83      0.63      0.72      1311\n",
            "    macro avg       0.66      0.48      0.54      1311\n",
            " weighted avg       0.83      0.63      0.71      1311\n",
            "  samples avg       0.05      0.05      0.05      1311\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "y_pred_probs = model.predict(x_test)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "# Generate the classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZqGtT1WIS6VO",
      "metadata": {
        "id": "ZqGtT1WIS6VO"
      },
      "source": [
        "## Encoder Only Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kcEUssvX1WVQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcEUssvX1WVQ",
        "outputId": "f74751b5-9f6f-4931-fda0-8b05d423206c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159571 entries, 0 to 159570\n",
            "Data columns (total 8 columns):\n",
            " #   Column         Non-Null Count   Dtype \n",
            "---  ------         --------------   ----- \n",
            " 0   id             159571 non-null  object\n",
            " 1   comment_text   159571 non-null  object\n",
            " 2   toxic          159571 non-null  int64 \n",
            " 3   severe_toxic   159571 non-null  int64 \n",
            " 4   obscene        159571 non-null  int64 \n",
            " 5   threat         159571 non-null  int64 \n",
            " 6   insult         159571 non-null  int64 \n",
            " 7   identity_hate  159571 non-null  int64 \n",
            "dtypes: int64(6), object(2)\n",
            "memory usage: 9.7+ MB\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "\n",
        "df = pd.read_csv(r\"train.csv\", encoding='iso-8859-1')\n",
        "df.info()\n",
        "df.head(n=5)\n",
        "\n",
        "df_data = df.sample(frac=0.2, replace=True, random_state=1)\n",
        "\n",
        "df_data.isnull().sum()\n",
        "\n",
        "wpt = nltk.WordPunctTokenizer()\n",
        "stop_words_init = nltk.corpus.stopwords.words('english')\n",
        "stop_words = [i for i in stop_words_init if i not in ('not','and','for')]\n",
        "print(stop_words)\n",
        "\n",
        "## Function to normalize text for pre-processing ##\n",
        "def normalize_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', ' ', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', ' ', text)\n",
        "    text = re.sub('<.*?>+', ' ', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
        "    text = re.sub('\\n', ' ', text)\n",
        "    text = re.sub('\\w*\\d\\w*', ' ', text)\n",
        "    return text\n",
        "\n",
        "## Apply the written function ##\n",
        "df_data['comment_text'] = df_data['comment_text'].apply(lambda x: normalize_text(x))\n",
        "\n",
        "df_data['comment_text'].head(n=5)\n",
        "\n",
        "processed_list = []\n",
        "for j in df_data['comment_text']:\n",
        "    process = j.replace('...','')\n",
        "    processed_list.append(process)\n",
        "\n",
        "df_processed = pd.DataFrame(processed_list)\n",
        "df_processed.columns = ['comments']\n",
        "df_processed.head(n=5)\n",
        "\n",
        "\n",
        "labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "targets = df_data[labels].values\n",
        "\n",
        "\n",
        "X = list(df_processed['comments'])\n",
        "y_data = df_data[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]]\n",
        "y = y_data.values\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.20, train_size=0.80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59503f55-c7d4-4026-b9d6-13ef3ec73cdd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59503f55-c7d4-4026-b9d6-13ef3ec73cdd",
        "outputId": "9f073394-de4e-4234-b358-17b1397fe9b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(None, 100)]             0         \n",
            "                                                                 \n",
            " embedding_9 (Embedding)     (None, 100, 200)          2000000   \n",
            "                                                                 \n",
            " transformer_encoder_layer_  (None, 100, 200)          1491312   \n",
            " 4 (TransformerEncoderLayer                                      \n",
            " )                                                               \n",
            "                                                                 \n",
            " transformer_encoder_layer_  (None, 100, 200)          1491312   \n",
            " 5 (TransformerEncoderLayer                                      \n",
            " )                                                               \n",
            "                                                                 \n",
            " transformer_encoder_layer_  (None, 100, 200)          1491312   \n",
            " 6 (TransformerEncoderLayer                                      \n",
            " )                                                               \n",
            "                                                                 \n",
            " transformer_encoder_layer_  (None, 100, 200)          1491312   \n",
            " 7 (TransformerEncoderLayer                                      \n",
            " )                                                               \n",
            "                                                                 \n",
            " layer_normalization_18 (La  (None, 100, 200)          400       \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " global_average_pooling1d_9  (None, 200)               0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 6)                 1206      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7966854 (30.39 MB)\n",
            "Trainable params: 5966854 (22.76 MB)\n",
            "Non-trainable params: 2000000 (7.63 MB)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "160/160 [==============================] - 63s 323ms/step - loss: 0.1534 - micro_f1_score: 0.8635 - val_loss: 0.1424 - val_micro_f1_score: 0.8950\n",
            "Epoch 2/15\n",
            "160/160 [==============================] - 50s 314ms/step - loss: 0.1419 - micro_f1_score: 0.8302 - val_loss: 0.1420 - val_micro_f1_score: 0.9179\n",
            "Epoch 3/15\n",
            "160/160 [==============================] - 50s 313ms/step - loss: 0.1418 - micro_f1_score: 0.8366 - val_loss: 0.1418 - val_micro_f1_score: 0.9114\n",
            "Epoch 4/15\n",
            "160/160 [==============================] - 51s 319ms/step - loss: 0.1405 - micro_f1_score: 0.8402 - val_loss: 0.1413 - val_micro_f1_score: 0.8197\n",
            "Epoch 5/15\n",
            "160/160 [==============================] - 51s 321ms/step - loss: 0.1405 - micro_f1_score: 0.8265 - val_loss: 0.1416 - val_micro_f1_score: 0.8850\n",
            "Epoch 6/15\n",
            "160/160 [==============================] - 51s 319ms/step - loss: 0.1405 - micro_f1_score: 0.8402 - val_loss: 0.1439 - val_micro_f1_score: 0.9727\n",
            "Epoch 7/15\n",
            "160/160 [==============================] - 50s 314ms/step - loss: 0.1400 - micro_f1_score: 0.8347 - val_loss: 0.1444 - val_micro_f1_score: 0.9874\n",
            "Epoch 8/15\n",
            "160/160 [==============================] - 51s 320ms/step - loss: 0.1401 - micro_f1_score: 0.8368 - val_loss: 0.1415 - val_micro_f1_score: 0.8452\n",
            "Epoch 9/15\n",
            "160/160 [==============================] - 51s 320ms/step - loss: 0.1398 - micro_f1_score: 0.8161 - val_loss: 0.1418 - val_micro_f1_score: 0.8474\n",
            "Epoch 10/15\n",
            "160/160 [==============================] - 51s 319ms/step - loss: 0.1404 - micro_f1_score: 0.8323 - val_loss: 0.1418 - val_micro_f1_score: 0.9076\n",
            "Epoch 11/15\n",
            "160/160 [==============================] - 51s 320ms/step - loss: 0.1402 - micro_f1_score: 0.8243 - val_loss: 0.1419 - val_micro_f1_score: 0.8809\n",
            "Epoch 12/15\n",
            "160/160 [==============================] - 50s 314ms/step - loss: 0.1397 - micro_f1_score: 0.8326 - val_loss: 0.1415 - val_micro_f1_score: 0.8485\n",
            "Epoch 13/15\n",
            "160/160 [==============================] - 50s 314ms/step - loss: 0.1398 - micro_f1_score: 0.8394 - val_loss: 0.1418 - val_micro_f1_score: 0.7863\n",
            "Epoch 14/15\n",
            "160/160 [==============================] - 50s 314ms/step - loss: 0.1400 - micro_f1_score: 0.8290 - val_loss: 0.1411 - val_micro_f1_score: 0.8482\n",
            "Epoch 15/15\n",
            "160/160 [==============================] - 51s 320ms/step - loss: 0.1400 - micro_f1_score: 0.8214 - val_loss: 0.1439 - val_micro_f1_score: 0.9776\n",
            "200/200 [==============================] - 6s 31ms/step - loss: 0.1401 - micro_f1_score: 0.6651\n",
            "Micro F1 Score:  0.6651247143745422\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, MultiHeadAttention, LayerNormalization, Dropout, Embedding, Input, Dense, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Textual Features for Embedding\n",
        "max_len = 100\n",
        "max_features = 10000\n",
        "embed_size = 200\n",
        "\n",
        "# Assume x_train and x_test are predefined\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(x_train) + list(x_test))\n",
        "\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_test = tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "x_train = pad_sequences(x_train, padding='post', maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, padding='post', maxlen=max_len)\n",
        "\n",
        "# Loading pre-trained GloVe embeddings\n",
        "embeddings_dictionary = {}\n",
        "with open('glove.twitter.27B.200d.txt', encoding=\"utf8\") as glove_file:\n",
        "    for line in glove_file:\n",
        "        records = line.split()\n",
        "        word = records[0]\n",
        "        vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
        "        embeddings_dictionary[word] = vector_dimensions\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "word_index = tokenizer.word_index\n",
        "num_words = min(max_features, len(word_index) + 1)\n",
        "\n",
        "embedding_matrix = np.zeros((num_words, embed_size))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index >= max_features:\n",
        "        continue\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector\n",
        "\n",
        "# Transformer Encoder Layer\n",
        "class TransformerEncoderLayer(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerEncoderLayer, self).__init__()\n",
        "        self.mha = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation='relu'),\n",
        "            Dense(embed_dim)\n",
        "        ])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "    def call(self, x, training):\n",
        "        attn_output = self.mha(x, x)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "# Building the Transformer Model\n",
        "embed_dim = embed_size  # Ensure this matches the embedding size\n",
        "num_heads = 8\n",
        "ff_dim = 512\n",
        "num_layers = 4\n",
        "\n",
        "sequence_input = Input(shape=(max_len,))\n",
        "embedding_layer = Embedding(num_words, embed_size, weights=[embedding_matrix], trainable=False)(sequence_input)\n",
        "x = embedding_layer\n",
        "\n",
        "for _ in range(num_layers):\n",
        "    x = TransformerEncoderLayer(embed_dim, num_heads, ff_dim)(x)\n",
        "\n",
        "x = LayerNormalization(epsilon=1e-6)(x)\n",
        "x = GlobalAveragePooling1D()(x)\n",
        "x = Dropout(0.1)(x)\n",
        "preds = Dense(6, activation='sigmoid')(x)\n",
        "sfc_loss = tfa.losses.SigmoidFocalCrossEntropy()\n",
        "model = Model(sequence_input, preds)\n",
        "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(1e-3), metrics=[micro_f1_score])\n",
        "print(model.summary())\n",
        "\n",
        "# Assuming y_train and y_test are predefined\n",
        "history = model.fit(x_train, y_train, batch_size=128, epochs=15, verbose=1, validation_split=0.2)\n",
        "\n",
        "model.save_weights(\"./Transformer_Ver1.h5\")\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "print(\"Micro F1 Score: \", score[1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "W2n6DrcxTA0y",
      "metadata": {
        "id": "W2n6DrcxTA0y"
      },
      "source": [
        "## Traditional Transformer  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mFOJse9cXbjA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFOJse9cXbjA",
        "outputId": "40d13365-1c5b-496e-ef13-25f2d61bc272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159571 entries, 0 to 159570\n",
            "Data columns (total 8 columns):\n",
            " #   Column         Non-Null Count   Dtype \n",
            "---  ------         --------------   ----- \n",
            " 0   id             159571 non-null  object\n",
            " 1   comment_text   159571 non-null  object\n",
            " 2   toxic          159571 non-null  int64 \n",
            " 3   severe_toxic   159571 non-null  int64 \n",
            " 4   obscene        159571 non-null  int64 \n",
            " 5   threat         159571 non-null  int64 \n",
            " 6   insult         159571 non-null  int64 \n",
            " 7   identity_hate  159571 non-null  int64 \n",
            "dtypes: int64(6), object(2)\n",
            "memory usage: 9.7+ MB\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "\n",
        "df = pd.read_csv(r\"train.csv\", encoding='iso-8859-1')\n",
        "df.info()\n",
        "df.head(n=5)\n",
        "\n",
        "df_data = df.sample(frac=0.2, replace=True, random_state=1)\n",
        "\n",
        "df_data.isnull().sum()\n",
        "\n",
        "wpt = nltk.WordPunctTokenizer()\n",
        "stop_words_init = nltk.corpus.stopwords.words('english')\n",
        "stop_words = [i for i in stop_words_init if i not in ('not','and','for')]\n",
        "print(stop_words)\n",
        "\n",
        "## Function to normalize text for pre-processing ##\n",
        "def normalize_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', ' ', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', ' ', text)\n",
        "    text = re.sub('<.*?>+', ' ', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
        "    text = re.sub('\\n', ' ', text)\n",
        "    text = re.sub('\\w*\\d\\w*', ' ', text)\n",
        "    return text\n",
        "\n",
        "## Apply the written function ##\n",
        "df_data['comment_text'] = df_data['comment_text'].apply(lambda x: normalize_text(x))\n",
        "\n",
        "df_data['comment_text'].head(n=5)\n",
        "\n",
        "processed_list = []\n",
        "for j in df_data['comment_text']:\n",
        "    process = j.replace('...','')\n",
        "    processed_list.append(process)\n",
        "\n",
        "df_processed = pd.DataFrame(processed_list)\n",
        "df_processed.columns = ['comments']\n",
        "df_processed.head(n=5)\n",
        "\n",
        "\n",
        "labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "targets = df_data[labels].values\n",
        "\n",
        "\n",
        "X = list(df_processed['comments'])\n",
        "y_data = df_data[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]]\n",
        "y = y_data.values\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.20, train_size=0.80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "D_jb5I76XQpB",
      "metadata": {
        "id": "D_jb5I76XQpB"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, MultiHeadAttention, LayerNormalization, Dropout, Embedding, Input, Dense, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Textual Features for Embedding\n",
        "max_len = 100\n",
        "max_features = 10000\n",
        "embed_size = 200\n",
        "\n",
        "# Assume x_train, x_test, y_train, y_test are predefined\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(x_train) + list(x_test))\n",
        "\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_test = tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "x_train = pad_sequences(x_train, padding='post', maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, padding='post', maxlen=max_len)\n",
        "\n",
        "# Loading pre-trained GloVe embeddings\n",
        "embeddings_dictionary = {}\n",
        "with open('glove.twitter.27B.200d.txt', encoding=\"utf8\") as glove_file:\n",
        "    for line in glove_file:\n",
        "        records = line.split()\n",
        "        word = records[0]\n",
        "        vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
        "        embeddings_dictionary[word] = vector_dimensions\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "word_index = tokenizer.word_index\n",
        "num_words = min(max_features, len(word_index) + 1)\n",
        "\n",
        "embedding_matrix = np.zeros((num_words, embed_size))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index >= max_features:\n",
        "        continue\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fWQasYGfEqSy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWQasYGfEqSy",
        "outputId": "14e873f8-30e9-445e-e4fd-d47b2e05cd2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_13 (InputLayer)       [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " embedding_12 (Embedding)    (None, 100, 200)             2000000   ['input_13[0][0]']            \n",
            "                                                                                                  \n",
            " positional_encoding_2 (Pos  (None, 100, 200)             0         ['embedding_12[0][0]']        \n",
            " itionalEncoding)                                                                                 \n",
            "                                                                                                  \n",
            " transformer_encoder_layer_  (None, 100, 200)             1491312   ['positional_encoding_2[0][0]'\n",
            " 12 (TransformerEncoderLaye                                         ]                             \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " transformer_encoder_layer_  (None, 100, 200)             1491312   ['transformer_encoder_layer_12\n",
            " 13 (TransformerEncoderLaye                                         [0][0]']                      \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " input_14 (InputLayer)       [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " transformer_encoder_layer_  (None, 100, 200)             1491312   ['transformer_encoder_layer_13\n",
            " 14 (TransformerEncoderLaye                                         [0][0]']                      \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " embedding_13 (Embedding)    (None, 100, 200)             2000000   ['input_14[0][0]']            \n",
            "                                                                                                  \n",
            " transformer_encoder_layer_  (None, 100, 200)             1491312   ['transformer_encoder_layer_14\n",
            " 15 (TransformerEncoderLaye                                         [0][0]']                      \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " positional_encoding_3 (Pos  (None, 100, 200)             0         ['embedding_13[0][0]']        \n",
            " itionalEncoding)                                                                                 \n",
            "                                                                                                  \n",
            " layer_normalization_49 (La  (None, 100, 200)             400       ['transformer_encoder_layer_15\n",
            " yerNormalization)                                                  [0][0]']                      \n",
            "                                                                                                  \n",
            " transformer_decoder_layer_  ((None, 100, 200),           2776712   ['positional_encoding_3[0][0]'\n",
            " 4 (TransformerDecoderLayer   (100, 200),                           , 'layer_normalization_49[0][0\n",
            " )                            (100, 200))                           ]']                           \n",
            "                                                                                                  \n",
            " transformer_decoder_layer_  ((None, 100, 200),           2776712   ['transformer_decoder_layer_4[\n",
            " 5 (TransformerDecoderLayer   (100, 200),                           0][0]',                       \n",
            " )                            (100, 200))                            'layer_normalization_49[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " transformer_decoder_layer_  ((None, 100, 200),           2776712   ['transformer_decoder_layer_5[\n",
            " 6 (TransformerDecoderLayer   (100, 200),                           0][0]',                       \n",
            " )                            (100, 200))                            'layer_normalization_49[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " transformer_decoder_layer_  ((None, 100, 200),           2776712   ['transformer_decoder_layer_6[\n",
            " 7 (TransformerDecoderLayer   (100, 200),                           0][0]',                       \n",
            " )                            (100, 200))                            'layer_normalization_49[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " layer_normalization_62 (La  (None, 100, 200)             400       ['transformer_decoder_layer_7[\n",
            " yerNormalization)                                                  0][0]']                       \n",
            "                                                                                                  \n",
            " global_average_pooling1d_1  (None, 200)                  0         ['layer_normalization_62[0][0]\n",
            " 1 (GlobalAveragePooling1D)                                         ']                            \n",
            "                                                                                                  \n",
            " dropout_68 (Dropout)        (None, 200)                  0         ['global_average_pooling1d_11[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_66 (Dense)            (None, 6)                    1206      ['dropout_68[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21074102 (80.39 MB)\n",
            "Trainable params: 17074102 (65.13 MB)\n",
            "Non-trainable params: 4000000 (15.26 MB)\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 187s 854ms/step - loss: 0.1512 - micro_f1_score: 0.8696 - val_loss: 0.1397 - val_micro_f1_score: 0.7493\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 144s 899ms/step - loss: 0.1419 - micro_f1_score: 0.8327 - val_loss: 0.1378 - val_micro_f1_score: 0.8836\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 143s 897ms/step - loss: 0.1420 - micro_f1_score: 0.8241 - val_loss: 0.1395 - val_micro_f1_score: 0.9573\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 144s 898ms/step - loss: 0.1411 - micro_f1_score: 0.8177 - val_loss: 0.1382 - val_micro_f1_score: 0.8342\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 144s 898ms/step - loss: 0.1405 - micro_f1_score: 0.8327 - val_loss: 0.1375 - val_micro_f1_score: 0.8333\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 143s 897ms/step - loss: 0.1404 - micro_f1_score: 0.8345 - val_loss: 0.1371 - val_micro_f1_score: 0.7946\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 143s 896ms/step - loss: 0.1404 - micro_f1_score: 0.8165 - val_loss: 0.1386 - val_micro_f1_score: 0.9248\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 144s 897ms/step - loss: 0.1404 - micro_f1_score: 0.8357 - val_loss: 0.1381 - val_micro_f1_score: 0.7851\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 143s 896ms/step - loss: 0.1402 - micro_f1_score: 0.8191 - val_loss: 0.1374 - val_micro_f1_score: 0.7940\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 144s 897ms/step - loss: 0.1403 - micro_f1_score: 0.8286 - val_loss: 0.1371 - val_micro_f1_score: 0.8316\n",
            "200/200 [==============================] - 17s 84ms/step - loss: 0.1412 - micro_f1_score: 0.6209\n",
            "Micro F1 Score:  0.6208774447441101\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout, Embedding, Input, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "# Transformer Encoder Layer\n",
        "class TransformerEncoderLayer(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerEncoderLayer, self).__init__()\n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation='relu'),\n",
        "            Dense(embed_dim)\n",
        "        ])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "    def call(self, x, training):\n",
        "        attn_output = self.mha(x, x)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "# Transformer Decoder Layer\n",
        "class TransformerDecoderLayer(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerDecoderLayer, self).__init__()\n",
        "        self.mha1 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.mha2 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation='relu'),\n",
        "            Dense(embed_dim)\n",
        "        ])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "        self.dropout3 = Dropout(rate)\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, x, enc_output, training, look_ahead_mask=None, padding_mask=None):\n",
        "        attn1 = self.mha1(x, x, x, attention_mask=look_ahead_mask)\n",
        "        attn1_output = attn1[0]  # Only take the first output, which is the attention output\n",
        "        attn1_output = self.dropout1(attn1_output, training=training)\n",
        "        out1 = self.layernorm1(attn1_output + x)\n",
        "\n",
        "        attn2 = self.mha2(enc_output, enc_output, out1, attention_mask=padding_mask)\n",
        "        attn2_output = attn2[0]  # Only take the first output, which is the attention output\n",
        "        attn2_output = self.dropout2(attn2_output, training=training)\n",
        "        out2 = self.layernorm2(attn2_output + out1)\n",
        "\n",
        "        ffn_output = self.ffn(out2)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(ffn_output + out2)\n",
        "\n",
        "        return out3, attn1[1], attn2[1]\n",
        "\n",
        "# Positional Encoding\n",
        "class PositionalEncoding(Layer):\n",
        "    def __init__(self, max_len, embed_dim):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.pos_encoding = self.positional_encoding(max_len, embed_dim)\n",
        "\n",
        "    def get_angles(self, pos, i, embed_dim):\n",
        "        angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(embed_dim))\n",
        "        return pos * angle_rates\n",
        "\n",
        "    def positional_encoding(self, max_len, embed_dim):\n",
        "        angle_rads = self.get_angles(np.arange(max_len)[:, np.newaxis], np.arange(embed_dim)[np.newaxis, :], embed_dim)\n",
        "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "        pos_encoding = angle_rads[np.newaxis, ...]\n",
        "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
        "\n",
        "# Building the Transformer Model with Encoder and Decoder\n",
        "embed_dim = embed_size  # Ensure this matches the embedding size\n",
        "num_heads = 8\n",
        "ff_dim = 512\n",
        "num_layers = 4\n",
        "\n",
        "sequence_input = Input(shape=(max_len,))\n",
        "embedding_layer = Embedding(num_words, embed_size, weights=[embedding_matrix], trainable=False)(sequence_input)\n",
        "pos_encoding_layer = PositionalEncoding(max_len, embed_dim)(embedding_layer)\n",
        "\n",
        "# Encoder\n",
        "x = pos_encoding_layer\n",
        "for _ in range(num_layers):\n",
        "    x = TransformerEncoderLayer(embed_dim, num_heads, ff_dim)(x)\n",
        "\n",
        "encoder_output = LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "# Decoder\n",
        "decoder_input = Input(shape=(max_len,))\n",
        "dec_embedding_layer = Embedding(num_words, embed_size, weights=[embedding_matrix], trainable=False)(decoder_input)\n",
        "dec_pos_encoding_layer = PositionalEncoding(max_len, embed_dim)(dec_embedding_layer)\n",
        "\n",
        "y = dec_pos_encoding_layer\n",
        "for _ in range(num_layers):\n",
        "    y, _, _ = TransformerDecoderLayer(embed_dim, num_heads, ff_dim)(y, encoder_output, training=True)\n",
        "\n",
        "y = LayerNormalization(epsilon=1e-6)(y)\n",
        "y = GlobalAveragePooling1D()(y)\n",
        "y = Dropout(0.1)(y)\n",
        "preds = Dense(6, activation='sigmoid')(y)\n",
        "sfc_loss = tfa.losses.SigmoidFocalCrossEntropy()\n",
        "model = Model([sequence_input, decoder_input], preds)\n",
        "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(1e-3), metrics=[micro_f1_score])\n",
        "print(model.summary())\n",
        "\n",
        "# Assuming y_train and y_test are predefined and for decoder input, typically shifted target sequence is used\n",
        "history = model.fit([x_train, x_train], y_train, batch_size=128, epochs=10, verbose=1, validation_split=0.2)\n",
        "\n",
        "model.save_weights(\"./Transformer_With_Decoder_Ver1.h5\")\n",
        "\n",
        "score = model.evaluate([x_test, x_test], y_test, verbose=1)\n",
        "\n",
        "print(\"Micro F1 Score: \", score[1])\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}